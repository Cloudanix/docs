---
slug: cloudtrail_global_services_logging_duplicated
title: Duplicate Entries Should Be Avoided In CloudTrail Logs
sidebar_label: Duplicate Entries Should Be Avoided In CloudTrail Logs
---

### More Info:

Only one trail within a CloudTrail multi-region logging configuration should have Include Global Services feature enabled in order to avoid duplicate log events being recorded for the AWS global services such as IAM, STS or Cloudfront.

### Risk Level

Medium

### Address

Security

### Compliance Standards

HIPAA



<Tabs><Tab title='Cause'>
### Check Cause

#### Using Console

1. Log in to the AWS Management Console and navigate to the CloudTrail service. 

2. In the CloudTrail dashboard, click on "Trails" in the left navigation pane. This will display a list of all the trails configured in your AWS account.

3. For each trail, check the "S3 Bucket" column. This column displays the name of the S3 bucket where the CloudTrail logs are stored. If you see the same S3 bucket name for multiple trails, it indicates that there are duplicate entries in the CloudTrail logs.

4. To further confirm, you can click on each trail and check the "Events" tab. If you see the same events logged multiple times, it confirms that there are duplicate entries in the CloudTrail logs.

#### Using CLI

1. **Install and Configure AWS CLI**: Before you can start using AWS CLI, you need to install it on your local system. You can download it from the official AWS website. After installation, you need to configure it with your AWS account using the command `aws configure`. You will be prompted to provide your AWS Access Key ID, Secret Access Key, Default region name, and Default output format.

2. **List Trails**: Use the `describe-trails` command to list all the trails for your AWS account. The command is as follows:

    ```
    aws cloudtrail describe-trails
    ```

    This command will return a JSON output with details of all the trails.

3. **Check for Duplicate Entries**: To check for duplicate entries, you can use the `lookup-events` command. This command looks up CloudTrail event logs and returns the events that match the specified lookup attributes. You can specify the lookup attributes as command line options. The command is as follows:

    ```
    aws cloudtrail lookup-events --lookup-attributes AttributeKey=EventName,AttributeValue=eventName
    ```

    Replace `eventName` with the name of the event you want to check for duplicates. This command will return a JSON output with details of all the events that match the specified lookup attributes.

4. **Analyze the Output**: The output of the `lookup-events` command will include a list of events. If there are duplicate entries for the same event, it means that the event has been logged more than once. You can use a Python script to parse the JSON output and identify duplicate entries. The script can use the `json` module to load the JSON output, and then use a dictionary to count the occurrences of each event. If the count of any event is more than 1, it means that there are duplicate entries for that event.

#### Using Python

1. Install the necessary Python libraries: Before you start, make sure you have the necessary Python libraries installed. You will need the boto3 library, which is the Amazon Web Services (AWS) SDK for Python. It allows Python developers to write software that makes use of services like Amazon S3, Amazon EC2, and others. You can install it using pip:

   ```python
   pip install boto3
   ```

2. Configure AWS Credentials: Boto3 needs your AWS credentials (access key and secret access key) to call AWS services on your behalf. You can configure it in several ways, but the simplest is to use the AWS CLI:

   ```bash
   aws configure
   ```

   Then input your Access Key ID, Secret Access Key, Default region name, and Default output format when prompted.

3. Create a Python script to check for duplicate entries: Now, you can create a Python script that uses boto3 to interact with CloudTrail and check for duplicate entries. Here's a simple example:

   ```python
   import boto3

   # Create CloudTrail client
   cloudtrail = boto3.client('cloudtrail')

   # Get the trail status
   response = cloudtrail.describe_trails()

   # Create an empty list to store the trail names
   trail_names = []

   # Loop through the trails
   for trail in response['trailList']:
       # If the trail name is already in the list, it's a duplicate
       if trail['Name'] in trail_names:
           print(f"Duplicate trail found: {trail['Name']}")
       else:
           # Otherwise, add it to the list
           trail_names.append(trail['Name'])
   ```

4. Run the Python script: Finally, you can run the Python script to check for duplicate entries in your CloudTrail logs. If any duplicates are found, they will be printed to the console. If no duplicates are found, the script will finish without printing anything.

   ```bash
   python check_duplicates.py
   ```

This script will help you identify if there are any duplicate trails in your AWS CloudTrail. However, it's important to note that this is a simple example and may need to be adjusted based on your specific needs and environment.

</Tab>


<Tab title='Remediation'>
### Remediation

#### Using Console

To remediate the duplicate entries issue in CloudTrail Logs in AWS using AWS Console, follow the below steps:

1. Open the AWS Management Console and navigate to the CloudTrail service.

2. In the CloudTrail dashboard, click on the Trails link on the left-hand side of the page.

3. Select the trail that you want to remediate and click on the Edit button.

4. Scroll down to the Event selectors section and click on the Edit button.

5. In the Edit event selector dialog box, you will see a list of all the AWS services that are being logged by CloudTrail. 

6. To avoid duplicate entries, you need to ensure that the same events are not being logged twice. 

7. For example, if you see that the "S3" service is being logged twice, you can uncheck one of the checkboxes to avoid duplicate entries.

8. Once you have made the necessary changes, click on the Save button to save the changes.

9. Verify that the duplicate entries have been remediated by checking the CloudTrail logs for the selected trail.

By following these steps, you will be able to remediate the duplicate entries issue in CloudTrail Logs in AWS using AWS Console.

#### Using CLI

To remediate duplicate entries in AWS CloudTrail logs using AWS CLI, follow these steps:

1. Open your AWS CLI and run the following command to get a list of all trails in your account:

   ```
   aws cloudtrail describe-trails
   ```

2. Identify the trail you want to modify and note down its name.

3. Run the following command to update the trail settings and enable log file validation:

   ```
   aws cloudtrail update-trail --name <trail-name> --enable-log-file-validation
   ```

   This will enable log file integrity validation, which helps detect and prevent duplicate entries in CloudTrail logs.

4. Next, run the following command to create a new S3 bucket policy that prevents overwriting existing log files:

   ```
   aws s3api put-bucket-policy --bucket <bucket-name> --policy '{
     "Version":"2012-10-17",
     "Statement":[
       {
         "Sid":"PreventOverwrite",
         "Effect":"Deny",
         "Principal": "*",
         "Action":[
           "s3:PutObject"
         ],
         "Resource":[
           "arn:aws:s3:::<bucket-name>/*"
         ],
         "Condition":{
           "StringEquals":{
             "s3:x-amz-acl":"bucket-owner-full-control"
           }
         }
       }
     ]
   }'
   ```

   Replace `<bucket-name>` with the name of the S3 bucket where your CloudTrail logs are stored.

   This policy denies any attempts to overwrite existing log files in the S3 bucket, which helps prevent duplicate entries.

5. Finally, run the following command to enable CloudTrail log file validation for the S3 bucket:

   ```
   aws cloudtrail put-event-selectors --trail-name <trail-name> --event-selectors '{
     "DataResources":[
       {
         "Type":"AWS::S3::Object",
         "Values":[
           "arn:aws:s3:::<bucket-name>/*"
         ]
       }
     ],
     "IncludeManagementEvents":true,
     "ReadWriteType":"All",
     "EnableLogFileValidation":true
   }'
   ```

   Replace `<trail-name>` and `<bucket-name>` with the appropriate values.

   This command enables log file validation for the specified S3 bucket and ensures that duplicate entries are detected and prevented in CloudTrail logs.

#### Using Python

To remediate duplicate entries in CloudTrail logs in AWS using Python, you can follow the below steps:

1. Install the AWS SDK for Python (Boto3) using the command `pip install boto3`.

2. Create a new Python file and import the necessary modules:

```
import boto3
from botocore.exceptions import ClientError
import json
```

3. Connect to the AWS CloudTrail service using the `boto3.client` method:

```
client = boto3.client('cloudtrail')
```

4. Retrieve the list of trails using the `describe_trails` method:

```
response = client.describe_trails()
```

5. Loop through the list of trails and retrieve the trail ARN for each trail:

```
for trail in response['trailList']:
    trail_arn = trail['TrailARN']
```

6. Retrieve the current CloudTrail settings for each trail using the `get_trail` method:

```
trail_response = client.get_trail(Name=trail_arn)
```

7. Check if the `S3KeyPrefix` parameter is set to a unique value for each trail:

```
if trail_response['S3KeyPrefix'] == 'AWSLogs/':
    print('S3KeyPrefix is set to the default value. Please update the value to a unique value.')
```

8. If the `S3KeyPrefix` parameter is set to the default value, update the value to a unique value using the `update_trail` method:

```
response = client.update_trail(
    Name=trail_arn,
    S3KeyPrefix='UniqueValue/'
)
```

9. Save and run the Python file to remediate the duplicate entries in CloudTrail logs for all the trails in your AWS account.

Note: You may need to modify the code to suit your specific requirements.

### Additional Reading:

- [https://aws.amazon.com/premiumsupport/knowledge-center/remove-duplicate-cloudtrail-events/](https://aws.amazon.com/premiumsupport/knowledge-center/remove-duplicate-cloudtrail-events/) 


</Tab>
</Tabs>