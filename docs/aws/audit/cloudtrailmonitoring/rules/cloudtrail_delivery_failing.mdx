---
slug: cloudtrail_delivery_failing
title: Log files Should Be Delivered Without Any Failures
sidebar_label: Log files Should Be Delivered Without Any Failures
---

### More Info:

The log files generated by your AWS CloudTrail trails should be delivered without any failures to designated recipients in order to keep CloudTrail logging data for security and compliance audits.

### Risk Level

Low

### Address

Reliability, Operational Maturity, Security

### Compliance Standards

CBP


### Triage and Remediation
<Tabs>


<Tab title='Prevention'>
### How to Prevent
<AccordionGroup>
<Accordion title='Using Console' defaultOpen='true'>
To prevent log files from being delivered without any failures in AWS CloudTrail using the AWS Management Console, follow these steps:

1. **Enable CloudTrail Logging:**
   - Open the AWS Management Console and navigate to the CloudTrail service.
   - Click on "Trails" in the left-hand menu.
   - Ensure that you have at least one trail created. If not, click "Create trail" and follow the prompts to set up a new trail.
   - Make sure the trail is set to apply to all regions to capture all activities across your AWS account.

2. **Configure S3 Bucket for Log Storage:**
   - In the CloudTrail trail settings, specify an S3 bucket where the log files will be stored.
   - Ensure that the S3 bucket has the correct permissions to allow CloudTrail to write logs to it. This typically involves setting up a bucket policy that grants the necessary permissions to the CloudTrail service.

3. **Enable CloudWatch Logs Integration:**
   - In the CloudTrail trail settings, enable integration with CloudWatch Logs.
   - Specify a CloudWatch Logs group where the logs will be delivered.
   - This allows you to monitor and alert on log delivery failures using CloudWatch Alarms.

4. **Set Up SNS Notifications for Log Delivery Failures:**
   - In the CloudTrail trail settings, configure an Amazon SNS topic to receive notifications about log delivery failures.
   - Create an SNS topic if you don't have one already.
   - Subscribe to the SNS topic with an email address or another endpoint to receive notifications in case of any issues with log delivery.

By following these steps, you can ensure that your CloudTrail logs are delivered reliably and that you are promptly notified of any delivery failures.
</Accordion>

<Accordion title='Using CLI'>
To ensure that log files are delivered without any failures in AWS CloudTrail using the AWS CLI, you can follow these steps:

1. **Enable CloudTrail Logging:**
   Ensure that CloudTrail is enabled and configured to log all necessary events.

   ```sh
   aws cloudtrail create-trail --name my-trail --s3-bucket-name my-trail-bucket
   ```

2. **Enable Multi-Region Trails:**
   Configure CloudTrail to log events from all regions to ensure comprehensive logging.

   ```sh
   aws cloudtrail update-trail --name my-trail --is-multi-region-trail
   ```

3. **Enable Log File Integrity Validation:**
   Enable log file integrity validation to ensure that the log files have not been tampered with.

   ```sh
   aws cloudtrail update-trail --name my-trail --enable-log-file-validation
   ```

4. **Configure SNS Notifications for Delivery Failures:**
   Set up an SNS topic to receive notifications if CloudTrail log delivery fails.

   ```sh
   aws sns create-topic --name CloudTrailLogDeliveryFailures
   aws cloudtrail update-trail --name my-trail --sns-topic-name CloudTrailLogDeliveryFailures
   ```

By following these steps, you can help ensure that your CloudTrail log files are delivered reliably and any issues are promptly reported.
</Accordion>

<Accordion title='Using Python'>
To ensure that log files are delivered without any failures in AWS CloudTrail using Python scripts, you can follow these steps:

### 1. Enable CloudTrail Logging
Ensure that CloudTrail is enabled and configured to log all necessary events.

```python
import boto3

# Create a CloudTrail client
client = boto3.client('cloudtrail')

# Enable CloudTrail logging
response = client.create_trail(
    Name='my-trail',
    S3BucketName='my-trail-bucket',
    IncludeGlobalServiceEvents=True,
    IsMultiRegionTrail=True,
    EnableLogFileValidation=True
)

# Start logging
client.start_logging(Name='my-trail')
print("CloudTrail logging enabled and started.")
```

### 2. Enable Log File Integrity Validation
Ensure that log file integrity validation is enabled to detect any modifications or deletions.

```python
# Enable log file validation
response = client.update_trail(
    Name='my-trail',
    EnableLogFileValidation=True
)
print("Log file integrity validation enabled.")
```

### 3. Monitor CloudTrail Logs Delivery Status
Set up a CloudWatch alarm to monitor the CloudTrail logs delivery status and trigger notifications if there are any issues.

```python
cloudwatch_client = boto3.client('cloudwatch')

# Create a CloudWatch alarm
response = cloudwatch_client.put_metric_alarm(
    AlarmName='CloudTrailLogDeliveryFailures',
    MetricName='DeliveryErrors',
    Namespace='AWS/CloudTrail',
    Statistic='Sum',
    Period=300,
    EvaluationPeriods=1,
    Threshold=1,
    ComparisonOperator='GreaterThanOrEqualToThreshold',
    AlarmActions=[
        'arn:aws:sns:us-east-1:123456789012:my-sns-topic'
    ],
    Dimensions=[
        {
            'Name': 'TrailName',
            'Value': 'my-trail'
        }
    ]
)
print("CloudWatch alarm for CloudTrail log delivery failures created.")
```

### 4. Automate Remediation with Lambda
Create an AWS Lambda function to automatically remediate any detected log delivery failures.

```python
lambda_client = boto3.client('lambda')

# Create a Lambda function
response = lambda_client.create_function(
    FunctionName='CloudTrailLogDeliveryFailureHandler',
    Runtime='python3.8',
    Role='arn:aws:iam::123456789012:role/my-lambda-role',
    Handler='lambda_function.lambda_handler',
    Code={
        'ZipFile': b"def lambda_handler(event, context):\n    print('Log delivery failure detected')\n    # Add remediation logic here"
    },
    Description='Handles CloudTrail log delivery failures',
    Timeout=300,
    MemorySize=128,
    Publish=True
)
print("Lambda function for handling CloudTrail log delivery failures created.")
```

By following these steps, you can ensure that CloudTrail log files are delivered without any failures and take proactive measures to monitor and remediate any issues that arise.
</Accordion>

</AccordionGroup>
</Tab>

<Tab title='Cause'>
### Check Cause
<AccordionGroup>
<Accordion title='Using Console' defaultOpen='true'>
1. Log in to the AWS Management Console and navigate to the CloudTrail service. 

2. In the CloudTrail dashboard, select "Trails" from the left-hand navigation pane. This will display a list of all the trails configured in your AWS account.

3. Select the trail you want to check for log delivery failures. This will open the trail's configuration page.

4. In the trail's configuration page, look for the "Last log file delivery" field. This field shows the time and date of the last successful log file delivery. If the delivery was unsuccessful, an error message will be displayed here.
</Accordion>

<Accordion title='Using CLI'>
1. **Install and Configure AWS CLI**: Before you can start using AWS CLI, you need to install it on your local system. You can download it from the official AWS website. After installation, you need to configure it with your AWS account credentials. You can do this by running the command `aws configure` and then entering your Access Key ID, Secret Access Key, Default region name, and Default output format when prompted.

2. **List Trails**: The first step to check if log files are being delivered without any failures is to list all the trails in your AWS account. You can do this by running the following command: `aws cloudtrail describe-trails`. This command will return a list of all the trails in your account.

3. **Get Trail Status**: For each trail returned by the previous command, you need to check its status. You can do this by running the following command: `aws cloudtrail get-trail-status --name <trail_name>`. Replace `<trail_name>` with the name of the trail you want to check. This command will return the status of the specified trail.

4. **Check Log File Validation**: In the output of the previous command, look for the `LogFileValidationEnabled` field. If its value is `true`, it means that log file validation is enabled for the trail, which is a good sign. However, if its value is `false`, it means that log file validation is not enabled, which could lead to log files being delivered with failures.
</Accordion>

<Accordion title='Using Python'>
1. **Import necessary libraries and establish a session**: To start with, you need to import the necessary libraries in your Python script. Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of AWS services like Amazon S3, Amazon EC2, etc. After importing the necessary libraries, establish a session using your AWS credentials.

```python
import boto3
from botocore.exceptions import BotoCoreError, ClientError

session = boto3.Session(
    aws_access_key_id='YOUR_ACCESS_KEY',
    aws_secret_access_key='YOUR_SECRET_KEY',
    region_name='us-west-2'
)
```

2. **Create a CloudTrail client**: After establishing a session, create a CloudTrail client. This client will help you interact with the CloudTrail service and fetch the necessary details.

```python
cloudtrail_client = session.client('cloudtrail')
```

3. **Fetch Trails and Check Log File Validation**: Now, fetch all the trails and check if the log file validation is enabled or not. If the log file validation is not enabled, it means there is a misconfiguration.

```python
try:
    response = cloudtrail_client.describe_trails()
    for trail in response['trailList']:
        if not trail['LogFileValidationEnabled']:
            print(f"Log file validation is not enabled for the trail: {trail['Name']}")
except ClientError as e:
    print(f"Unexpected error: {e}")
```

4. **Check for Delivery Failures**: Finally, check for any delivery failures in the CloudTrail logs. If there are any delivery failures, it means there is a misconfiguration.

```python
try:
    response = cloudtrail_client.get_trail_status(Name='TrailName')
    if response['IsLogging']:
        if response['LatestDeliveryError']:
            print(f"Delivery error: {response['LatestDeliveryError']}")
    else:
        print("Logging is not enabled.")
except ClientError as e:
    print(f"Unexpected error: {e}")
```

Please replace 'TrailName' with the actual name of your trail. Also, replace 'YOUR_ACCESS_KEY' and 'YOUR_SECRET_KEY' with your actual AWS access key and secret key.
</Accordion>

</AccordionGroup>
</Tab>

<Tab title='Remediation'>
### Remediation

<AccordionGroup>
<Accordion title='Using Console' defaultOpen='true'>
To remediate the misconfiguration "Log files should be delivered without any failures" for AWS using AWS console, follow the below steps:

1. Open the AWS Management Console and navigate to the CloudWatch service.

2. Click on "Logs" in the left-hand menu and select the log group that is experiencing the delivery failure.

3. Click on the "Actions" drop-down menu and select "Stream to Amazon Elasticsearch Service".

4. In the "Stream to Amazon Elasticsearch Service" dialog box, select the Elasticsearch domain that you want to stream the log data to.

5. Choose the appropriate IAM role that has permission to stream the log data to the Elasticsearch domain.

6. Configure the log stream settings as required and click on "Start Streaming".

7. Once the log stream is successfully started, CloudWatch will begin delivering log data to the Elasticsearch domain without any failures.

8. You can monitor the log stream status and troubleshoot any issues using the CloudWatch Logs console.

By following these steps, you can remediate the misconfiguration "Log files should be delivered without any failures" for AWS using AWS console.

#
</Accordion>

<Accordion title='Using CLI'>
To remediate the misconfiguration "Log files Should Be Delivered Without Any Failures" in AWS, you can follow the below steps using AWS CLI:

1. Open the AWS CLI on your local machine or terminal.

2. Run the following command to create a new S3 bucket to store the logs:

   ```
   aws s3api create-bucket --bucket <bucket-name> --region <region> --create-bucket-configuration LocationConstraint=<region>
   ```

   Replace `<bucket-name>` with your desired bucket name and `<region>` with the region in which you want to create the bucket.

3. Run the following command to enable access logging for your S3 bucket:

   ```
   aws s3api put-bucket-acl --bucket <bucket-name> --grant-read uri=http://acs.amazonaws.com/groups/s3/LogDelivery --grant-write uri=http://acs.amazonaws.com/groups/s3/LogDelivery --grant-read-acp uri=http://acs.amazonaws.com/groups/s3/LogDelivery --grant-write-acp uri=http://acs.amazonaws.com/groups/s3/LogDelivery --grant-full-control uri=http://acs.amazonaws.com/groups/s3/LogDelivery
   ```

   Replace `<bucket-name>` with the name of the bucket you created in step 2.

4. Run the following command to create a new CloudWatch Logs group:

   ```
   aws logs create-log-group --log-group-name <log-group-name>
   ```

   Replace `<log-group-name>` with your desired name for the log group.

5. Run the following command to create a new CloudWatch Logs stream:

   ```
   aws logs create-log-stream --log-group-name <log-group-name> --log-stream-name <log-stream-name>
   ```

   Replace `<log-group-name>` with the name of the log group you created in step 4 and `<log-stream-name>` with your desired name for the log stream.

6. Run the following command to create a new CloudWatch Logs subscription filter:

   ```
   aws logs put-subscription-filter --log-group-name <log-group-name> --filter-name <filter-name> --filter-pattern "" --destination-arn arn:aws:s3:::<bucket-name>
   ```

   Replace `<log-group-name>` with the name of the log group you created in step 4, `<filter-name>` with your desired name for the filter, and `<bucket-name>` with the name of the S3 bucket you created in step 2.

7. Verify that the logs are being delivered to the S3 bucket by checking the contents of the bucket. You should see log files being created and updated in real-time.

By following these steps, you can remediate the misconfiguration "Log files Should Be Delivered Without Any Failures" in AWS using AWS CLI.
</Accordion>

<Accordion title='Using Python'>
To remediate the misconfiguration "Log files Should Be Delivered Without Any Failures" for AWS using Python, you can follow these steps:

Step 1: Create an S3 bucket to store the log files.

```
import boto3

s3 = boto3.client('s3')

bucket_name = 'your-bucket-name'

s3.create_bucket(Bucket=bucket_name)
```

Step 2: Create an IAM role with permissions to write to the S3 bucket.

```
import boto3

iam = boto3.client('iam')

role_name = 'your-role-name'

assume_role_policy_document = {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "logs.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}

response = iam.create_role(
    RoleName=role_name,
    AssumeRolePolicyDocument=json.dumps(assume_role_policy_document)
)

policy_document = {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:PutObject"
            ],
            "Resource": [
                "arn:aws:s3:::your-bucket-name/*"
            ]
        }
    ]
}

iam.put_role_policy(
    RoleName=role_name,
    PolicyName='your-policy-name',
    PolicyDocument=json.dumps(policy_document)
)
```

Step 3: Create a CloudWatch Logs subscription filter to deliver the log files to the S3 bucket.

```
import boto3

logs = boto3.client('logs')

log_group_name = 'your-log-group-name'
filter_name = 'your-filter-name'
destination_arn = 'arn:aws:s3:::your-bucket-name'

response = logs.put_subscription_filter(
    logGroupName=log_group_name,
    filterName=filter_name,
    filterPattern='',
    destinationArn=destination_arn,
    roleArn='arn:aws:iam::your-account-id:role/your-role-name'
)
```

Note: Replace the placeholders (your-bucket-name, your-role-name, your-policy-name, your-log-group-name, your-filter-name, and your-account-id) with your own values.

These steps will remediate the misconfiguration "Log files Should Be Delivered Without Any Failures" for AWS using Python.
</Accordion>

</AccordionGroup>
</Tab>
</Tabs>
### Additional Reading:

- [https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-cli.html](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-cli.html) 

