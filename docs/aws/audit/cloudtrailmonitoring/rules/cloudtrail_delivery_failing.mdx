---
slug: cloudtrail_delivery_failing
title: Log files Should Be Delivered Without Any Failures
sidebar_label: Log files Should Be Delivered Without Any Failures
---

### More Info:

The log files generated by your AWS CloudTrail trails should be delivered without any failures to designated recipients in order to keep CloudTrail logging data for security and compliance audits.

### Risk Level

Low

### Address

Reliability, Operational Maturity, Security

### Compliance Standards

CBP


### Triage and Remediation
<Tabs>

<Tab title='Cause'>
### Check Cause
<AccordionGroup>
<Accordion title='Using Console' defaultOpen='true'>
1. Log in to the AWS Management Console and navigate to the CloudTrail service. 

2. In the CloudTrail dashboard, select "Trails" from the left-hand navigation pane. This will display a list of all the trails configured in your AWS account.

3. Select the trail you want to check for log delivery failures. This will open the trail's configuration page.

4. In the trail's configuration page, look for the "Last log file delivery" field. This field shows the time and date of the last successful log file delivery. If the delivery was unsuccessful, an error message will be displayed here.
</Accordion>

<Accordion title='Using CLI'>
1. **Install and Configure AWS CLI**: Before you can start using AWS CLI, you need to install it on your local system. You can download it from the official AWS website. After installation, you need to configure it with your AWS account credentials. You can do this by running the command `aws configure` and then entering your Access Key ID, Secret Access Key, Default region name, and Default output format when prompted.

2. **List Trails**: The first step to check if log files are being delivered without any failures is to list all the trails in your AWS account. You can do this by running the following command: `aws cloudtrail describe-trails`. This command will return a list of all the trails in your account.

3. **Get Trail Status**: For each trail returned by the previous command, you need to check its status. You can do this by running the following command: `aws cloudtrail get-trail-status --name <trail_name>`. Replace `<trail_name>` with the name of the trail you want to check. This command will return the status of the specified trail.

4. **Check Log File Validation**: In the output of the previous command, look for the `LogFileValidationEnabled` field. If its value is `true`, it means that log file validation is enabled for the trail, which is a good sign. However, if its value is `false`, it means that log file validation is not enabled, which could lead to log files being delivered with failures.
</Accordion>

<Accordion title='Using Python'>
1. **Import necessary libraries and establish a session**: To start with, you need to import the necessary libraries in your Python script. Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of AWS services like Amazon S3, Amazon EC2, etc. After importing the necessary libraries, establish a session using your AWS credentials.

```python
import boto3
from botocore.exceptions import BotoCoreError, ClientError

session = boto3.Session(
    aws_access_key_id='YOUR_ACCESS_KEY',
    aws_secret_access_key='YOUR_SECRET_KEY',
    region_name='us-west-2'
)
```

2. **Create a CloudTrail client**: After establishing a session, create a CloudTrail client. This client will help you interact with the CloudTrail service and fetch the necessary details.

```python
cloudtrail_client = session.client('cloudtrail')
```

3. **Fetch Trails and Check Log File Validation**: Now, fetch all the trails and check if the log file validation is enabled or not. If the log file validation is not enabled, it means there is a misconfiguration.

```python
try:
    response = cloudtrail_client.describe_trails()
    for trail in response['trailList']:
        if not trail['LogFileValidationEnabled']:
            print(f"Log file validation is not enabled for the trail: {trail['Name']}")
except ClientError as e:
    print(f"Unexpected error: {e}")
```

4. **Check for Delivery Failures**: Finally, check for any delivery failures in the CloudTrail logs. If there are any delivery failures, it means there is a misconfiguration.

```python
try:
    response = cloudtrail_client.get_trail_status(Name='TrailName')
    if response['IsLogging']:
        if response['LatestDeliveryError']:
            print(f"Delivery error: {response['LatestDeliveryError']}")
    else:
        print("Logging is not enabled.")
except ClientError as e:
    print(f"Unexpected error: {e}")
```

Please replace 'TrailName' with the actual name of your trail. Also, replace 'YOUR_ACCESS_KEY' and 'YOUR_SECRET_KEY' with your actual AWS access key and secret key.
</Accordion>

</AccordionGroup>
</Tab>

<Tab title='Remediation'>
### Remediation

<AccordionGroup>
<Accordion title='Using Console' defaultOpen='true'>
To remediate the misconfiguration "Log files should be delivered without any failures" for AWS using AWS console, follow the below steps:

1. Open the AWS Management Console and navigate to the CloudWatch service.

2. Click on "Logs" in the left-hand menu and select the log group that is experiencing the delivery failure.

3. Click on the "Actions" drop-down menu and select "Stream to Amazon Elasticsearch Service".

4. In the "Stream to Amazon Elasticsearch Service" dialog box, select the Elasticsearch domain that you want to stream the log data to.

5. Choose the appropriate IAM role that has permission to stream the log data to the Elasticsearch domain.

6. Configure the log stream settings as required and click on "Start Streaming".

7. Once the log stream is successfully started, CloudWatch will begin delivering log data to the Elasticsearch domain without any failures.

8. You can monitor the log stream status and troubleshoot any issues using the CloudWatch Logs console.

By following these steps, you can remediate the misconfiguration "Log files should be delivered without any failures" for AWS using AWS console.

#
</Accordion>

<Accordion title='Using CLI'>
To remediate the misconfiguration "Log files Should Be Delivered Without Any Failures" in AWS, you can follow the below steps using AWS CLI:

1. Open the AWS CLI on your local machine or terminal.

2. Run the following command to create a new S3 bucket to store the logs:

   ```
   aws s3api create-bucket --bucket <bucket-name> --region <region> --create-bucket-configuration LocationConstraint=<region>
   ```

   Replace `<bucket-name>` with your desired bucket name and `<region>` with the region in which you want to create the bucket.

3. Run the following command to enable access logging for your S3 bucket:

   ```
   aws s3api put-bucket-acl --bucket <bucket-name> --grant-read uri=http://acs.amazonaws.com/groups/s3/LogDelivery --grant-write uri=http://acs.amazonaws.com/groups/s3/LogDelivery --grant-read-acp uri=http://acs.amazonaws.com/groups/s3/LogDelivery --grant-write-acp uri=http://acs.amazonaws.com/groups/s3/LogDelivery --grant-full-control uri=http://acs.amazonaws.com/groups/s3/LogDelivery
   ```

   Replace `<bucket-name>` with the name of the bucket you created in step 2.

4. Run the following command to create a new CloudWatch Logs group:

   ```
   aws logs create-log-group --log-group-name <log-group-name>
   ```

   Replace `<log-group-name>` with your desired name for the log group.

5. Run the following command to create a new CloudWatch Logs stream:

   ```
   aws logs create-log-stream --log-group-name <log-group-name> --log-stream-name <log-stream-name>
   ```

   Replace `<log-group-name>` with the name of the log group you created in step 4 and `<log-stream-name>` with your desired name for the log stream.

6. Run the following command to create a new CloudWatch Logs subscription filter:

   ```
   aws logs put-subscription-filter --log-group-name <log-group-name> --filter-name <filter-name> --filter-pattern "" --destination-arn arn:aws:s3:::<bucket-name>
   ```

   Replace `<log-group-name>` with the name of the log group you created in step 4, `<filter-name>` with your desired name for the filter, and `<bucket-name>` with the name of the S3 bucket you created in step 2.

7. Verify that the logs are being delivered to the S3 bucket by checking the contents of the bucket. You should see log files being created and updated in real-time.

By following these steps, you can remediate the misconfiguration "Log files Should Be Delivered Without Any Failures" in AWS using AWS CLI.
</Accordion>

<Accordion title='Using Python'>
To remediate the misconfiguration "Log files Should Be Delivered Without Any Failures" for AWS using Python, you can follow these steps:

Step 1: Create an S3 bucket to store the log files.

```
import boto3

s3 = boto3.client('s3')

bucket_name = 'your-bucket-name'

s3.create_bucket(Bucket=bucket_name)
```

Step 2: Create an IAM role with permissions to write to the S3 bucket.

```
import boto3

iam = boto3.client('iam')

role_name = 'your-role-name'

assume_role_policy_document = {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "logs.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}

response = iam.create_role(
    RoleName=role_name,
    AssumeRolePolicyDocument=json.dumps(assume_role_policy_document)
)

policy_document = {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:PutObject"
            ],
            "Resource": [
                "arn:aws:s3:::your-bucket-name/*"
            ]
        }
    ]
}

iam.put_role_policy(
    RoleName=role_name,
    PolicyName='your-policy-name',
    PolicyDocument=json.dumps(policy_document)
)
```

Step 3: Create a CloudWatch Logs subscription filter to deliver the log files to the S3 bucket.

```
import boto3

logs = boto3.client('logs')

log_group_name = 'your-log-group-name'
filter_name = 'your-filter-name'
destination_arn = 'arn:aws:s3:::your-bucket-name'

response = logs.put_subscription_filter(
    logGroupName=log_group_name,
    filterName=filter_name,
    filterPattern='',
    destinationArn=destination_arn,
    roleArn='arn:aws:iam::your-account-id:role/your-role-name'
)
```

Note: Replace the placeholders (your-bucket-name, your-role-name, your-policy-name, your-log-group-name, your-filter-name, and your-account-id) with your own values.

These steps will remediate the misconfiguration "Log files Should Be Delivered Without Any Failures" for AWS using Python.
</Accordion>

</AccordionGroup>
</Tab>
</Tabs>
### Additional Reading:

- [https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-cli.html](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-cli.html) 

