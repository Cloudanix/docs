---
slug: s3_https
title: S3 Buckets Should Have A Secure Transport Policy
sidebar_label: S3 Buckets Should Have A Secure Transport Policy
---

### More Info:

AWS S3 buckets should enforce encryption of data over the network (as it travels to and from Amazon S3) using Secure Sockets Layer (SSL).

### Risk Level

Critical

### Address

Security

### Compliance Standards

HIPAA, CISAWS, CBP, GDPR, NIST, SOC2, PCIDSS, ISO27001, AWSWAF, HITRUST, NISTCSF


### Triage and Remediation
<Tabs>

<Tab title='Cause'>
### Check Cause
<AccordionGroup>
<Accordion title='Using Console' defaultOpen='true'>
1. Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.
   
2. In the Bucket name list, choose the name of the bucket that you want to check for a secure transport policy.

3. Choose the Permissions tab, and then choose Bucket Policy. 

4. In the Bucket policy editor, look for a statement with "Condition": `{ "Bool": { "aws:SecureTransport": "false" } }`. If this statement is present, it means that the bucket has a secure transport policy. If it's not present, the bucket does not have a secure transport policy.
</Accordion>

<Accordion title='Using CLI'>
1. Install and configure AWS CLI: Before you can start using AWS CLI, you need to install it on your local machine. You can download it from the official AWS website. After installation, you need to configure it with your AWS account credentials. You can do this by running the command `aws configure` and then entering your Access Key ID, Secret Access Key, Default region name, and Default output format when prompted.

2. List all S3 buckets: Use the following command to list all the S3 buckets in your AWS account.

   ```
   aws s3api list-buckets --query 'Buckets[].Name'
   ```

3. Check the bucket policy: For each bucket, you need to check if it has a secure transport policy. You can do this by running the following command for each bucket.

   ```
   aws s3api get-bucket-policy --bucket your-bucket-name
   ```

4. Analyze the output: The output of the above command will be a JSON object representing the bucket's policy. You need to check if this policy includes a statement with `"Effect": "Deny"` and `"Condition": { "Bool": { "aws:SecureTransport": "false" } }`. This statement ensures that all requests to the bucket must be made over SSL. If this statement is not present, then the bucket does not have a secure transport policy.
</Accordion>

<Accordion title='Using Python'>
1. First, you need to install the AWS SDK for Python (Boto3) if you haven't done so already. You can install it using pip:

```python
pip install boto3
```

2. Import the necessary modules and create a session using your AWS credentials:

```python
import boto3

session = boto3.Session(
    aws_access_key_id='YOUR_ACCESS_KEY',
    aws_secret_access_key='YOUR_SECRET_KEY',
    region_name='YOUR_REGION'
)
```

3. Now, create a client for 's3' and get the list of all the buckets:

```python
s3 = session.client('s3')
response = s3.list_buckets()

buckets = [bucket['Name'] for bucket in response['Buckets']]
```

4. For each bucket, get the bucket policy and check if it has a Secure Transport statement:

```python
for bucket in buckets:
    try:
        bucket_policy = s3.get_bucket_policy(Bucket=bucket)
        policy = json.loads(bucket_policy['Policy'])

        for statement in policy['Statement']:
            if statement['Sid'] == 'ForceSSLOnlyAccess':
                if statement['Effect'] == 'Deny' and 'aws:SecureTransport' in statement['Condition']['Bool'] and statement['Condition']['Bool']['aws:SecureTransport'] == 'false':
                    print(f"Bucket {bucket} has a secure transport policy.")
                else:
                    print(f"Bucket {bucket} does not have a secure transport policy.")
    except:
        print(f"Bucket {bucket} does not have a policy.")
```

This script will print out whether each bucket has a secure transport policy or not. If a bucket does not have a policy or if the policy does not include a statement with Sid 'ForceSSLOnlyAccess' that denies access when 'aws:SecureTransport' is 'false', it will be flagged as not having a secure transport policy.
</Accordion>

</AccordionGroup>
</Tab>

<Tab title='Remediation'>
### Remediation

<AccordionGroup>
<Accordion title='Using Console' defaultOpen='true'>
1. Open the [AWS S3 Console](https://s3.console.aws.amazon.com/).
2. Navigate to the specific S3 bucket for which you want to enforce secure transport.
3. Click on the "Permissions" tab.
4. Scroll down to the "Bucket policy" section.
5. Edit the bucket policy to enforce the use of HTTPS.

Here is an example policy snippet to enforce HTTPS:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Deny",
            "Principal": "*",
            "Action": "*",
            "Resource": [
                "arn:aws:s3:::YOUR_BUCKET_NAME/*",
                "arn:aws:s3:::YOUR_BUCKET_NAME"
            ],
            "Condition": {
                "Bool": {
                    "aws:SecureTransport": "false"
                }
            }
        }
    ]
}
```


Replace `YOUR_BUCKET_NAME` with the name of your S3 bucket.

#
</Accordion>

<Accordion title='Using CLI'>
```bash
# Run the following AWS CLI command to update the bucket policy to enforce HTTPS
aws s3api put-bucket-policy --bucket YOUR_BUCKET_NAME --policy '{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Deny",
      "Principal": "*",
      "Action": "*",
      "Resource": ["arn:aws:s3:::YOUR_BUCKET_NAME/*", "arn:aws:s3:::YOUR_BUCKET_NAME"],
      "Condition": {
        "Bool": {
          "aws:SecureTransport": "false"
        }
      }
    }
  ]
}'
```


Replace `YOUR_BUCKET_NAME` with the name of your S3 bucket.
</Accordion>

<Accordion title='Using Python'>
```python
import boto3

def remediate_s3_secure_transport_policy(bucket_name, aws_access_key_id, aws_secret_access_key, region):
    # Create an S3 client
    s3_client = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key, region_name=region)

    # Bucket policy to enforce secure transport (HTTPS)
    bucket_policy = {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Effect": "Deny",
                "Principal": "*",
                "Action": "*",
                "Resource": [
                    f"arn:aws:s3:::{bucket_name}/*",
                    f"arn:aws:s3:::{bucket_name}"
                ],
                "Condition": {
                    "Bool": {
                        "aws:SecureTransport": "false"
                    }
                }
            }
        ]
    }

    # Apply the bucket policy
    s3_client.put_bucket_policy(
        Bucket=bucket_name,
        Policy=json.dumps(bucket_policy)
    )

    print(f"Secure transport policy (HTTPS) enforced for S3 bucket: {bucket_name}")

# Example usage
bucket_name = 'YOUR_BUCKET_NAME'
aws_access_key_id = 'YOUR_ACCESS_KEY'
aws_secret_access_key = 'YOUR_SECRET_KEY'
region = 'us-east-1'  # Replace with your desired region

remediate_s3_secure_transport_policy(bucket_name, aws_access_key_id, aws_secret_access_key, region)
```


Replace `YOUR_BUCKET_NAME`, `YOUR_ACCESS_KEY`, `YOUR_SECRET_KEY`, and update the `region` with your desired region in the Python script. Run the script, and it will enforce the use of HTTPS for the specified S3 bucket. Make sure to install the `boto3` library if you haven't already:

```bash
pip install boto3
```

Note: Ensure that you have the necessary permissions to make these changes, and exercise caution when applying changes to production environments.
</Accordion>

</AccordionGroup>
</Tab>
</Tabs>
### Additional Reading:

- [https://docs.aws.amazon.com/AmazonS3/latest/userguide/security-best-practices.html](https://docs.aws.amazon.com/AmazonS3/latest/userguide/security-best-practices.html) 

