---
slug: bigquery_datasets_not_publicly_accessible
title: Ensure that BigQuery datasets are not anonymously or publicly accessible
sidebar_label: Ensure that BigQuery datasets are not anonymously or publicly accessible
---

### More Info:

It is recommended that the IAM policy on BigQuery datasets does not allow anonymous and/or public access.

### Risk Level

Medium

### Address

Security

### Compliance Standards

CISGCP, CBP, HITRUST, GDPR, SOC2, NISTCSF, PCIDSS, FedRAMP


### Triage and Remediation
<Tabs>

<Tab title='Cause'>
### Check Cause
<AccordionGroup>
<Accordion title='Using Console' defaultOpen='true'>
1. Login to your Google Cloud Platform (GCP) Console: Open your browser and navigate to the GCP Console (console.cloud.google.com) and sign in with your GCP account credentials.

2. Navigate to BigQuery: From the left-hand side menu, select "BigQuery" under the "Big Data" section. This will take you to the BigQuery interface.

3. Check Dataset Permissions: In the BigQuery interface, select a dataset from the resources panel on the left. Once selected, click on the "SHARE DATASET" button at the top of the page. This will open a new window showing the current access controls for the dataset.

4. Review Access Controls: In the access controls window, look for any entries where the "Identity" field is set to "allAuthenticatedUsers" or "allUsers". These settings mean that the dataset is accessible to all authenticated users or to the public, respectively. If you find any such entries, it indicates that the dataset is anonymously or publicly accessible.
</Accordion>

<Accordion title='Using CLI'>
1. Install and configure the Google Cloud SDK CLI (gcloud) on your local machine. You can do this by following the instructions provided by Google Cloud at https://cloud.google.com/sdk/docs/install.

2. Once the gcloud CLI is installed and configured, you can list all the BigQuery datasets in your project by running the following command:

   ```
   gcloud bigquery datasets list --format="value(datasetReference.datasetId)"
   ```
   This command will return a list of all dataset IDs in your project.

3. For each dataset ID returned by the previous command, you can check the access control settings by running the following command:

   ```
   gcloud bigquery datasets describe [DATASET_ID] --format="value(access)"
   ```
   Replace `[DATASET_ID]` with the ID of the dataset you want to check. This command will return a list of all entities that have access to the dataset and their roles.

4. To detect if a dataset is anonymously or publicly accessible, look for any of the following in the output of the previous command:

   - `specialGroup: allAuthenticatedUsers` - This means that any authenticated user has access to the dataset.
   - `specialGroup: allUsers` - This means that the dataset is publicly accessible, i.e., anyone, even without authentication, can access the dataset.

   If you see either of these in the access control settings for a dataset, it means that the dataset is anonymously or publicly accessible.
</Accordion>

<Accordion title='Using Python'>
1. Install the necessary Python libraries: You will need the `google-cloud-bigquery` library to interact with BigQuery. You can install it using pip:

```python
pip install google-cloud-bigquery
```

2. Import the necessary libraries and initialize the BigQuery client:

```python
from google.cloud import bigquery

# Initialize a BigQuery client
client = bigquery.Client()
```

3. Fetch all datasets and check their Access Control Lists (ACLs):

```python
# Get all datasets in the project
datasets = list(client.list_datasets())

# Loop through each dataset
for dataset in datasets:
    # Get the dataset's ACL
    acl = client.get_dataset(dataset.dataset_id).access_entries

    # Check if the dataset is publicly accessible
    for entry in acl:
        if entry.role == 'READER' and entry.entity_id == 'allUsers':
            print(f"Dataset {dataset.dataset_id} is publicly accessible.")
        elif entry.role == 'READER' and entry.entity_id == 'allAuthenticatedUsers':
            print(f"Dataset {dataset.dataset_id} is accessible by any authenticated user.")
```

4. The above script will print out the names of all datasets that are either publicly accessible or accessible by any authenticated user. If no such datasets exist, the script will not output anything. This way, you can easily detect any misconfigurations in your BigQuery datasets.
</Accordion>

</AccordionGroup>
</Tab>

<Tab title='Remediation'>
### Remediation

<AccordionGroup>
<Accordion title='Using Console' defaultOpen='true'>
To remediate this misconfiguration in GCP using GCP console, you can follow these steps:

1. Open the GCP console and navigate to the BigQuery section.

2. Click on the dataset that you want to remediate.

3. In the dataset details page, click on the "Share dataset" button.

4. In the "Share dataset" dialog box, review the current access controls.

5. If the dataset is publicly accessible, click on the "X" next to the "allUsers" entry to remove it.

6. If the dataset is anonymously accessible, click on the "X" next to the "allAuthenticatedUsers" entry to remove it.

7. If you want to grant access to specific users or groups, click on the "Add item" button and enter their email addresses.

8. Choose the appropriate access level for the users or groups, such as "Viewer" or "Editor".

9. Click on the "Save" button to apply the changes.

10. Finally, verify that the dataset is no longer publicly or anonymously accessible by reviewing the access controls again.

#
</Accordion>

<Accordion title='Using CLI'>
To remediate the misconfiguration of BigQuery datasets being anonymously or publicly accessible in GCP using GCP CLI, follow these steps:

1. Open the Cloud Shell from the GCP console.
2. Run the following command to list all the datasets in your project:
```
bq ls
```
3. For each dataset that is publicly accessible, run the following command to revoke the public access:
```
bq update --default_table_expiration <dataset_id>
```
Note: Replace `<dataset_id>` with the ID of the dataset that you want to remediate.

4. After running the above command, you will see the following prompt:
```
This update will modify table(s) <dataset_id>:*. Do you want to continue? (y/N):
```
5. Type `y` and press enter to confirm the update.

6. Repeat steps 3-5 for all the datasets that are publicly accessible.

7. Run the following command to verify that the datasets are no longer publicly accessible:
```
bq show <dataset_id>
```
Note: Replace `<dataset_id>` with the ID of the dataset that you want to verify.

8. Verify that the `defaultTableExpirationMs` field is set to `-1` in the output. This indicates that the dataset is not publicly accessible.

9. Repeat step 8 for all the datasets that you have remediated.

By following these steps, you can remediate the misconfiguration of BigQuery datasets being anonymously or publicly accessible in GCP using GCP CLI.
</Accordion>

<Accordion title='Using Python'>
To remediate the misconfiguration of BigQuery datasets being publicly accessible, you can use the following Python code:

1. First, you need to authenticate and authorize your Python script to access the Google Cloud Platform. For this, you can use the `google-auth` and `google-auth-oauthlib` libraries. Here is an example of how to authenticate and authorize:

```
from google.oauth2 import service_account
from google.auth.transport.requests import AuthorizedSession

# Load the service account credentials
credentials = service_account.Credentials.from_service_account_file(
    'path/to/service_account.json'
)

# Create an authorized session using the credentials
session = AuthorizedSession(credentials)
```

2. Once you have authenticated and authorized your script, you can use the `google-cloud-bigquery` library to access the BigQuery API. Here is an example of how to check if a dataset is publicly accessible:

```
from google.cloud import bigquery

# Create a BigQuery client
client = bigquery.Client()

# Get the dataset reference
dataset_ref = client.dataset('my_dataset')

# Get the dataset metadata
dataset = client.get_dataset(dataset_ref)

# Check if the dataset is publicly accessible
if dataset.acl_entries:
    for entry in dataset.acl_entries:
        if entry.role == 'READER' and entry.entity_type == 'userByEmail' and entry.entity_id == '':
            print('Dataset is publicly accessible')
```

3. If the dataset is publicly accessible, you can revoke the public access by removing the `READER` role for the anonymous user. Here is an example of how to do this:

```
from google.cloud import bigquery

# Create a BigQuery client
client = bigquery.Client()

# Get the dataset reference
dataset_ref = client.dataset('my_dataset')

# Get the dataset metadata
dataset = client.get_dataset(dataset_ref)

# Remove the public access
if dataset.acl_entries:
    for entry in dataset.acl_entries:
        if entry.role == 'READER' and entry.entity_type == 'userByEmail' and entry.entity_id == '':
            dataset.acl_entries.remove(entry)
            client.update_dataset(dataset, ['acl_entries'])
            print('Public access revoked')
```

By following these steps, you can remediate the misconfiguration of BigQuery datasets being publicly accessible in GCP using Python.
</Accordion>

</AccordionGroup>
</Tab>
</Tabs>
### Additional Reading:

- [https://cloud.google.com/bigquery/docs/dataset-access-controls](https://cloud.google.com/bigquery/docs/dataset-access-controls) 

