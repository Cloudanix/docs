

<Tabs><Tab title='Cause'>
### Check Cause

#### Using Console

1. Log in to the Google Cloud Platform Console: Open your web browser and navigate to the Google Cloud Platform Console (console.cloud.google.com). Enter your login credentials to access your GCP account.

2. Navigate to the Cloud Storage: From the GCP Console dashboard, click on the navigation menu (three horizontal lines) located at the top left corner of the page. Scroll down and click on "Storage" under the "Storage" section.

3. Access the Bucket Details: You will see a list of all your storage buckets. Click on the name of the bucket that you want to check for global access. This will take you to the bucket details page.

4. Check the Permissions: On the bucket details page, click on the "Permissions" tab. Here, you can see all the permissions associated with the bucket. If you see any permission with "allUsers" or "allAuthenticatedUsers" as members, it means the bucket allows global access.

#### Using CLI

1. Install and configure the Google Cloud SDK CLI on your local machine. You can download it from the official Google Cloud website and follow the instructions to set it up.

2. Once the SDK is installed and configured, open your terminal or command prompt and use the following command to list all the buckets in your GCP project:

   ```
   gsutil ls
   ```

   This command will return a list of all the buckets in your project.

3. To check the IAM policy of a specific bucket, use the following command:

   ```
   gsutil iam get gs://[BUCKET_NAME]
   ```

   Replace `[BUCKET_NAME]` with the name of the bucket you want to check. This command will return the IAM policy of the bucket in a JSON format.

4. In the returned JSON, look for the `bindings` array. If there is a binding with the `role` set to `roles/storage.objectViewer` and the `members` array includes `allUsers` or `allAuthenticatedUsers`, then the bucket allows global access. Here is an example of such a binding:

   ```
   {
     "role": "roles/storage.objectViewer",
     "members": [
       "allUsers"
     ]
   }
   ```

   If such a binding exists, then the bucket is misconfigured and allows global access.

#### Using Python

1. Install the necessary Python libraries: Before you can start writing the script, you need to install the necessary Python libraries. For AWS, you would need boto3, for Azure, you would need azure-storage-blob and for GCP, you would need google-cloud-storage. You can install these libraries using pip.

```python
pip install boto3 azure-storage-blob google-cloud-storage
```

2. Connect to the cloud service: The next step is to connect to the cloud service. You would need to authenticate your script with the cloud service. Here is how you can do it for each cloud service:

AWS:
```python
import boto3
s3 = boto3.resource('s3')
```

Azure:
```python
from azure.storage.blob import BlobServiceClient
blob_service_client = BlobServiceClient.from_connection_string("your_connection_string")
```

GCP:
```python
from google.cloud import storage
client = storage.Client()
```

3. List all the buckets: Once you have connected to the cloud service, you can list all the buckets. Here is how you can do it:

AWS:
```python
for bucket in s3.buckets.all():
    print(bucket.name)
```

Azure:
```python
for container in blob_service_client.list_containers():
    print(container.name)
```

GCP:
```python
for bucket in client.list_buckets():
    print(bucket.name)
```

4. Check the bucket permissions: The final step is to check the permissions of each bucket. If a bucket allows global access, it is a misconfiguration. Here is how you can check it:

AWS:
```python
for bucket in s3.buckets.all():
    acl = bucket.Acl()
    for grant in acl.grants:
        if grant['Grantee']['Type'] == 'Group' and 'AllUsers' in grant['Grantee']['URI']:
            print(f"Bucket {bucket.name} allows global access")
```

Azure:
```python
for container in blob_service_client.list_containers():
    acl = blob_service_client.get_container_access_policy(container.name)
    if acl.public_access:
        print(f"Container {container.name} allows global access")
```

GCP:
```python
for bucket in client.list_buckets():
    policy = bucket.get_iam_policy()
    for role in policy:
        if 'allUsers' in policy[role]:
            print(f"Bucket {bucket.name} allows global access")
```

</Tab>

<Tab title='Remediation'>
### Remediation

#### Using Console

To remediate the "Bucket Should Not Allow Global Access" misconfiguration for GCP using GCP console, follow these steps:

1. Go to the GCP console and select the project that contains the bucket with global access.

2. Navigate to the Cloud Storage section of the console.

3. Find the bucket that is allowing global access and click on its name to open its details page.

4. Click on the "Permissions" tab.

5. Scroll down to the "Public access prevention" section and click on the "Edit" button.

6. In the "Public access prevention" window, select the "Enforced by Bucket Policy" option.

7. Click on the "Save" button to apply the changes.

8. Next, click on the "Bucket Policy" tab.

9. In the bucket policy editor, enter the following JSON code to deny all public access to the bucket:

```
{
  "bindings": [
    {
      "members": [
        "allUsers"
      ],
      "role": "roles/storage.objectViewer"
    }
  ],
  "effect": "deny",
  "condition": {
    "bool": {
      "values": [
        true
      ]
    }
  }
}
```

10. Click on the "Save" button to apply the policy.

After following these steps, the bucket will no longer allow global access and all public access will be denied.

#### Using CLI

To remediate the bucket should not allow global access misconfiguration in GCP using GCP CLI, follow these steps:

1. Open the Google Cloud Console and navigate to the Cloud Shell.

2. Run the following command to list all the buckets in your project:

   ```
   gsutil ls
   ```

3. Identify the bucket that has global access enabled.

4. Run the following command to remove the public access from the bucket:

   ```
   gsutil iam ch allUsers:objectViewer gs://[BUCKET_NAME]
   ```

   Replace [BUCKET_NAME] with the name of the bucket that you identified in step 3.

5. Run the following command to verify that the public access has been removed:

   ```
   gsutil iam get gs://[BUCKET_NAME]
   ```

   This command will display the IAM policy for the bucket. Verify that the "allUsers" entity no longer has the "roles/storage.objectViewer" role.

6. Repeat steps 3 to 5 for all the buckets in your project that have global access enabled.

By following these steps, you can remediate the bucket should not allow global access misconfiguration in GCP using GCP CLI.

#### Using Python

To remediate the "Bucket Should Not Allow Global Access" misconfiguration in GCP using Python, you can follow the below steps:

Step 1: Install and import the required libraries
```
!pip install google-cloud-storage
from google.cloud import storage
```

Step 2: Authenticate with GCP using service account credentials
```
storage_client = storage.Client.from_service_account_json('path/to/service_account.json')
```

Step 3: Get the bucket object that you want to remediate
```
bucket_name = "your-bucket-name"
bucket = storage_client.get_bucket(bucket_name)
```

Step 4: Set the bucket's IAM policy to deny all public access
```
policy = bucket.get_iam_policy(requested_policy_version=3)
policy.bindings.append(
    {
        "role": "roles/storage.objectViewer",
        "members": {"allUsers"},
        "condition": {
            "title": "Deny access to objects if they are not authenticated",
            "description": "Requests from user accounts without authentication are not allowed.",
            "expression": "request.auth != null",
        },
    }
)
bucket.set_iam_policy(policy)
```

Step 5: Verify that the bucket's IAM policy has been updated to deny all public access
```
policy = bucket.get_iam_policy(requested_policy_version=3)
for binding in policy.bindings:
    if binding["role"] == "roles/storage.objectViewer" and "allUsers" in binding["members"]:
        print("Global access has been denied.")
```

By following these steps, you can remediate the "Bucket Should Not Allow Global Access" misconfiguration in GCP using Python.


</Tab>
</Tabs>