---
slug: storage_bucket_logs_not_public
title: Storage Bucket Logs Should Not be Publicly Accessible
sidebar_label: Storage Bucket Logs Should Not be Publicly Accessible
---

### More Info:

Ensure that cloud Storage bucket Logs are not Publicly Accessible by setting "publicAccessPrevention" to "enforced".

### Risk Level

High

### Address

Security

### Compliance Standards

HITRUST, SOC2, NISTCSF, PCIDSS


<Tabs><Tab title='Cause'>
### Check Cause

#### Using Console

1. Log in to the Google Cloud Platform Console: Open your web browser, navigate to the Google Cloud Platform Console (https://console.cloud.google.com/), and sign in with your Google account credentials.

2. Navigate to the Storage Browser: From the GCP Console Dashboard, select the project you want to inspect. Then, from the left-side menu, navigate to "Storage" > "Browser".

3. Check Bucket Permissions: For each bucket listed in the "Buckets" section, click on the three-dot menu on the right side of the bucket name and select "Edit bucket permissions". This will open a new page displaying the permissions associated with the bucket.

4. Inspect Public Access: In the "Permissions" tab, look for entries where the "Members" field is set to "allUsers" or "allAuthenticatedUsers". If such entries exist, it means that the bucket logs are publicly accessible.

#### Using CLI

1. Install and configure the Google Cloud SDK CLI on your local machine. You can do this by following the instructions provided by Google Cloud at https://cloud.google.com/sdk/docs/install.

2. Once the SDK is installed and configured, open your terminal and use the following command to list all the buckets in your project:

   ```
   gsutil ls -p [PROJECT_ID]
   ```
   Replace `[PROJECT_ID]` with your actual project ID.

3. For each bucket, check the Access Control List (ACL) to see if it is publicly accessible. You can do this by running the following command:

   ```
   gsutil acl get gs://[BUCKET_NAME]
   ```
   Replace `[BUCKET_NAME]` with the name of each bucket you want to check.

4. If the output of the above command includes `READER: AllUsers` or `READER: AllAuthenticatedUsers`, then the bucket is publicly accessible. This is the misconfiguration that needs to be addressed.

#### Using Python

1. AWS S3:
   - Install the AWS SDK (boto3) for Python. You can do this by running `pip install boto3`.
   - Use the following Python script to check if any S3 bucket has public access:

```python
import boto3

s3 = boto3.client('s3')

def check_public_buckets():
    response = s3.list_buckets()
    for bucket in response['Buckets']:
        acl = s3.get_bucket_acl(Bucket=bucket['Name'])
        for grant in acl['Grants']:
            if grant['Grantee']['Type'] == 'Group' and 'AllUsers' in grant['Grantee']['URI']:
                print(f"Bucket {bucket['Name']} is publicly accessible")

check_public_buckets()
```

2. Azure Blob Storage:
   - Install the Azure SDK for Python. You can do this by running `pip install azure-storage-blob`.
   - Use the following Python script to check if any Blob Storage has public access:

```python
from azure.storage.blob import BlobServiceClient

blob_service_client = BlobServiceClient.from_connection_string("my_connection_string")

def check_public_containers():
    all_containers = blob_service_client.list_containers(include_metadata=True)
    for container in all_containers:
        acl = blob_service_client.get_container_access_policy(container.name)
        if acl.public_access:
            print(f"Container {container.name} is publicly accessible")

check_public_containers()
```

3. Google Cloud Storage (GCS):
   - Install the Google Cloud SDK for Python. You can do this by running `pip install google-cloud-storage`.
   - Use the following Python script to check if any GCS bucket has public access:

```python
from google.cloud import storage

storage_client = storage.Client()

def check_public_buckets():
    for bucket in storage_client.list_buckets():
        policy = bucket.get_iam_policy()
        for role in policy:
            members = policy[role]
            for member in members:
                if member == 'allUsers' or member == 'allAuthenticatedUsers':
                    print(f"Bucket {bucket.name} is publicly accessible")

check_public_buckets()
```

Remember to replace `"my_connection_string"` with your actual Azure connection string. Also, ensure that you have the necessary permissions and the correct configuration for accessing the resources in all three cloud platforms.

</Tab>


<Tab title='Remediation'>
### Remediation

#### Using Console

Sure, I can help you with that. Here are the step by step instructions to remediate the issue "Storage Bucket Logs Should Not be Publicly Accessible" for GCP using GCP Console:

1. Open the GCP Console and navigate to the Cloud Storage page.

2. Select the bucket that you want to remediate.

3. Click on the "Permissions" tab.

4. Under the "Public access prevention" section, click on the "Edit" button.

5. Set the "Prevent public access" toggle to "On".

6. Click on the "Save" button to save the changes.

7. Under the "Access control" section, click on the "Add members" button.

8. Enter the email address of the user or service account that you want to grant access to.

9. Select the appropriate role from the "Select a role" dropdown menu.

10. Click on the "Add" button to add the member and role.

11. Repeat steps 7-10 for each user or service account that you want to grant access to.

12. Click on the "Save" button to save the changes.

By following these steps, you have successfully remediated the issue "Storage Bucket Logs Should Not be Publicly Accessible" for GCP using GCP Console.

#### Using CLI

To remediate the issue of publicly accessible storage bucket logs in GCP, you can follow the below steps using GCP CLI:

1. Open the Cloud Shell in your GCP console.

2. Run the following command to list all the storage buckets in your GCP project:

   ```
   gsutil ls
   ```

3. Identify the bucket that contains the logs which are publicly accessible.

4. Run the following command to update the bucket's permissions and make it private:

   ```
   gsutil iam ch -d allUsers gs://[BUCKET_NAME]
   ```
   Replace `[BUCKET_NAME]` with the name of the bucket that you identified in step 3.

5. Verify that the bucket's permissions have been updated by running the following command:

   ```
   gsutil iam get gs://[BUCKET_NAME]
   ```
   It should return the updated IAM policy for the bucket.

6. Finally, you can check if the bucket logs are still publicly accessible by trying to access them using a web browser or any other tool. If the remediation was successful, you should not be able to access the logs anymore.

Note: Make sure that you have the necessary permissions to modify the IAM policies of the storage buckets in your GCP project.

#### Using Python

To remediate the issue of publicly accessible storage bucket logs in GCP, you can use the following Python code:

```python
from google.cloud import storage

# Set the name of the bucket and the name of the log object
bucket_name = "your-bucket-name"
log_object_name = "your-log-object-name"

# Create a client object
client = storage.Client()

# Get the bucket object
bucket = client.get_bucket(bucket_name)

# Get the log object
log_object = bucket.get_blob(log_object_name)

# Set the log object's access control to private
log_object.acl.save_predefined('private')
```

Explanation:

1. Import the necessary libraries, including the `google.cloud.storage` library.
2. Set the name of the bucket and the name of the log object that you want to remediate.
3. Create a client object to interact with the GCP storage service.
4. Get the bucket object using the client and the bucket name.
5. Get the log object using the bucket and the log object name.
6. Set the log object's access control to private using the `save_predefined()` method of the `acl` attribute of the log object.

Note: You will need to have the necessary permissions to modify the access control of the log object in order to successfully remediate this issue.




</Tab>
</Tabs>